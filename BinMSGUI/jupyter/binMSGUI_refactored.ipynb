{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the required Python Modules (and modules created for BinMSGUI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "import struct\n",
    "import json\n",
    "import datetime\n",
    "import scipy\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# this will obtain the path for the notebook\n",
    "# if you have moved the notebook, you will need to set the notebook_path to the\n",
    "# .../BinMSGUI/BinMSGUI/jupyter directory\n",
    "notebook_path = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# the code path is two folders up from this notebook + /code\n",
    "core_path = os.path.dirname(notebook_path)\n",
    "basepath = os.path.dirname(os.path.dirname(notebook_path))\n",
    "\n",
    "# add the core_path and basepath so we can import core.module_name\n",
    "sys.path.append(core_path)\n",
    "sys.path.append(basepath)\n",
    "\n",
    "# import the binMSGUI modules\n",
    "from core.readMDA import readMDA, get_Fs\n",
    "from core.readBin import get_bin_data, get_raw_pos, get_active_tetrode, get_channel_from_tetrode, get_active_eeg\n",
    "from core.Tint_Matlab import int16toint8, get_setfile_parameter\n",
    "from core.tetrode_conversion import convert_tetrode, batch_basename_tetrodes\n",
    "from core.convert_position import convert_position\n",
    "from core.eeg_conversion import convert_eeg\n",
    "from core.utils import find_sub, find_bin_basenames\n",
    "from core.bin2mda import convert_bin2mda\n",
    "from core.mdaSort import sort_bin\n",
    "from core.set_conversion import convert_setfile\n",
    "from core.intan_mountainsort import validate_session, convert_bin_mountainsort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Directory Containing .Bin Files to Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 basename(s) within this directory: C:\\Users\\geba\\Desktop\\5MinRecording\n",
      "------------------------\n",
      "20171020-RAW-5MIN\n"
     ]
    }
   ],
   "source": [
    "# directory that you want to analyze\n",
    "directory = r'C:\\Users\\geba\\Desktop\\5MinRecording'\n",
    "\n",
    "# finds the basenames within this directory\n",
    "basenames = find_bin_basenames(directory)\n",
    "\n",
    "# prints all the basenames\n",
    "print('Found %d basename(s) within this directory: %s' % (len(basenames), directory))\n",
    "print('------------------------')\n",
    "for name in basenames:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis Parameters\n",
    "This cell will contain all the parameters that are required for the analysis. There are quite a few so make sure that you check that the parameters are correct before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### filtering parameters ###########\n",
    "# The .bin data is already filtered based upon whatever settings you chose in the dacqUSB, therefore this\n",
    "# is just for show and does not do anything. If you want me to add an actual filtering step feel free to\n",
    "# let me know, right now this is just for show.\n",
    "\n",
    "freq_min = 300  # -units Hz- default 300\n",
    "freq_max = 7000  # -units Hz- default 7000\n",
    "notch_filter = False  # the data is already notch filtered likely\n",
    "\n",
    "########## Clip Parameters ##############\n",
    "pre_spike = 15\n",
    "post_spike = 35\n",
    "clip_size = 50 # this needs to be left at 50 for Tint, Tint only likes 50 samples\n",
    "if (pre_spike + post_spike != clip_size) or (clip_size != 50):\n",
    "    raise Exception('The pre_spike and the post_spike must add up to be 50, and the clip size must remain at 50 for Tint!')\n",
    "\n",
    "############ whiten ####################\n",
    "# do you want to whiten the data? The MountainSort Paper suggests that spatial whitening is crucial\n",
    "# for separating nearby clusters since it will remove any correlations among channels. Keep in mind\n",
    "# that spatial whitening will also normalize your data so when you threshold you will be thresholding\n",
    "# based off of # of standard deviations, and not a bit/uV value.\n",
    "# if you want to whiten, set whiten='true', if you do not set whiten='false'\n",
    "whiten = 'true' \n",
    "# whiten = 'false'\n",
    "\n",
    "############# detect_sign ################\n",
    "# recommend only doing positive peaks so we don't get any weird issues with a cell that is\n",
    "# aligned with the peak, and seemingly the same cell aligned with the trough (in this case\n",
    "# both peak and trough would have to exceed the threshold).\n",
    "\n",
    "# detect_sign = 0  # positive or negative peaks\n",
    "detect_sign = 1  # only positive peaks\n",
    "# detect_sign = -1  # only negative peaks\n",
    "\n",
    "########## detect_interval ##############\n",
    "# the algorithm will take the detect_interval value and bin the data in bin sizes of that many\n",
    "# samples. Then it will find the peak (or trough, or both) of each bin and evaluate that event\n",
    "# if it exceeds the threshold value. Therefore the detect_interval is roughly the number of \n",
    "# samples between the events (peaks/troughs depending on your detect_sign)\n",
    "\n",
    "# default detect_interval is 50\n",
    "\n",
    "# detect_interval = 50 \n",
    "detect_interval = 20  \n",
    "\n",
    "############ detect_threshold ###############\n",
    "\n",
    "# threshold values, I changed it into a whitened and non whitened threshold\n",
    "# this is because if you whiten the data you normalize it by the variance, thus\n",
    "# a threshold of 3 is essentially saying 3 standard deviations. However if you do not whiten\n",
    "# the data is not normalized and thus, you would be using a bit value, maybe should take whatever\n",
    "# value is in the threshold from the set file.\n",
    "\n",
    "automate_threshold = False  # Don't Change this, here we are just initializing the automate_threshold value to False by default\n",
    "\n",
    "if whiten == 'true':\n",
    "    # detect_threshold = 3  # units: ~sd's\n",
    "    detect_threshold = 4  # units: ~sd's\n",
    "    \n",
    "else:\n",
    "    # this mean's the data was not whitened\n",
    "    \n",
    "    detect_threshold = 13000  #  units: bits \n",
    "    \n",
    "    # if you want to find the threshold from the .set file and use that \n",
    "    # set automate_threshold to True, otherwise False. This threshold would override any\n",
    "    # value set above. I'd recommend setting this to true as this is variable from .set file\n",
    "    # to .set file it seems.\n",
    "    # automate_threshold = True \n",
    "    automate_threshold = False\n",
    "\n",
    "# ########### artifact masking parameters ###########\n",
    "# here we bin the data into masked_chunk_size bins, and it will take the sqrt of the sum of \n",
    "# the squares (RSS) for each bin. It will then find the SD for all the bins, and if the bin is\n",
    "# above mask_threshold SD's from the average bin RSS, it will consider it as high amplitude noise\n",
    "# and remove this chunk (and neighboring chunks).\n",
    "\n",
    "# mask = True  # set the value to True if you want to include the artifact masking step\n",
    "mask = False  # set the value to False if you want to skip the artifact masking step\n",
    "mask_threshold = 6  #  units: SD's, the threshold that once exceed the bin/chunk will be zero'ed (and the neighbors)\n",
    "\n",
    "# the size of the bins/chunks to use when binning the data. If the value is set to  None \n",
    "# the defaul tmasked_chunk_size it will default to Fs/20\n",
    "masked_chunk_size = None  \n",
    "\n",
    "mask_num_write_chunks = 100  # how many chunks will be simultaneously written to the masked output file\n",
    "\n",
    "########## Feature/PCA Parameters ##########\n",
    "num_features = 10\n",
    "max_num_clips_for_pca = 1000\n",
    "\n",
    "# random parameters, probably don't need to change\n",
    "self = None  # don't worry about this, this is for objective oriented programming (my GUIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runs Analysis on each Basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing set_file 1/1: \n",
      "Using the following detect_threshold: 4.00\n",
      "[2019-08-22 17:52:17]: The following set file has already been created: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_ms.set, skipping creation!#Red\n",
      "[2019-08-22 17:52:17]: Converting the following tetrode: 1!\n",
      "[2019-08-22 17:52:24]: The following filename already exists: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T1_filt.mda, skipping conversion!#Red\n",
      "[2019-08-22 17:52:24]: Converting the following tetrode: 2!\n",
      "[2019-08-22 17:52:29]: The following filename already exists: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T2_filt.mda, skipping conversion!#Red\n",
      "[2019-08-22 17:52:29]: Converting the following tetrode: 3!\n",
      "[2019-08-22 17:52:34]: The following filename already exists: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T3_filt.mda, skipping conversion!#Red\n",
      "[2019-08-22 17:52:34]: Converting the following tetrode: 4!\n",
      "[2019-08-22 17:52:38]: The following filename already exists: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T4_filt.mda, skipping conversion!#Red\n",
      "ml-run-process ms4_geoff.sort --inputs filt_fname:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T1_filt.mda --outputs firings_out:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T1_firings.mda pre_out_fname:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T1_pre.mda metrics_out_fname:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T1_metrics.json --parameters freq_min:300 freq_max:7000 samplerate:48000 detect_sign:1 adjacency_radius:-1 detect_threshold:4 detect_interval:20 clip_size:50 firing_rate_thresh:0.05 isolation_thresh:0.95 noise_overlap_thresh:0.03 peak_snr_thresh:1.5 mask_artifacts:false mask_chunk_size:4800 mask_threshold:6 mask_num_write_chunks:100 num_workers:12 whiten:true num_features:10 max_num_clips_for_pca:3000 >> /mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T1_terminal.txt\n",
      "ml-run-process ms4_geoff.sort --inputs filt_fname:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T2_filt.mda --outputs firings_out:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T2_firings.mda pre_out_fname:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T2_pre.mda metrics_out_fname:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T2_metrics.json --parameters freq_min:300 freq_max:7000 samplerate:48000 detect_sign:1 adjacency_radius:-1 detect_threshold:4 detect_interval:20 clip_size:50 firing_rate_thresh:0.05 isolation_thresh:0.95 noise_overlap_thresh:0.03 peak_snr_thresh:1.5 mask_artifacts:false mask_chunk_size:4800 mask_threshold:6 mask_num_write_chunks:100 num_workers:12 whiten:true num_features:10 max_num_clips_for_pca:3000 >> /mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T2_terminal.txt\n",
      "ml-run-process ms4_geoff.sort --inputs filt_fname:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T3_filt.mda --outputs firings_out:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T3_firings.mda pre_out_fname:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T3_pre.mda metrics_out_fname:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T3_metrics.json --parameters freq_min:300 freq_max:7000 samplerate:48000 detect_sign:1 adjacency_radius:-1 detect_threshold:4 detect_interval:20 clip_size:50 firing_rate_thresh:0.05 isolation_thresh:0.95 noise_overlap_thresh:0.03 peak_snr_thresh:1.5 mask_artifacts:false mask_chunk_size:4800 mask_threshold:6 mask_num_write_chunks:100 num_workers:12 whiten:true num_features:10 max_num_clips_for_pca:3000 >> /mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T3_terminal.txt\n",
      "ml-run-process ms4_geoff.sort --inputs filt_fname:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T4_filt.mda --outputs firings_out:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T4_firings.mda pre_out_fname:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T4_pre.mda metrics_out_fname:/mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T4_metrics.json --parameters freq_min:300 freq_max:7000 samplerate:48000 detect_sign:1 adjacency_radius:-1 detect_threshold:4 detect_interval:20 clip_size:50 firing_rate_thresh:0.05 isolation_thresh:0.95 noise_overlap_thresh:0.03 peak_snr_thresh:1.5 mask_artifacts:false mask_chunk_size:4800 mask_threshold:6 mask_num_write_chunks:100 num_workers:12 whiten:true num_features:10 max_num_clips_for_pca:3000 >> /mnt/c/Users/geba/Desktop/5MinRecording/20171020-RAW-5MIN_T4_terminal.txt\n",
      "[2019-08-22 17:58:35]: Analyzing the following bin file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN.bin!\n",
      "[2019-08-22 17:58:35]: Reading in the position data!\n",
      "[2019-08-22 17:58:35]: Creating the .pos file!\n",
      "[2019-08-22 17:58:35]: Converting the MountainSort output following filename to Tint: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T1_filt.mda\n",
      "[2019-08-22 17:58:35]: Reading the spike data from the following file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T1_firings.mda\n",
      "[2019-08-22 17:58:35]: Reading the spike data from the following file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T1_firings.mda\n",
      "[2019-08-22 17:58:39]: Creating the following tetrode file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_ms.1!\n",
      "[2019-08-22 17:58:39]: Creating the following cut file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_ms_1.cut!\n",
      "[2019-08-22 17:58:40]: Converting the MountainSort output following filename to Tint: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T2_filt.mda\n",
      "[2019-08-22 17:58:40]: Reading the spike data from the following file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T2_firings.mda\n",
      "[2019-08-22 17:58:40]: Reading the spike data from the following file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T2_firings.mda\n",
      "[2019-08-22 17:58:43]: Creating the following tetrode file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_ms.2!\n",
      "[2019-08-22 17:58:44]: Creating the following cut file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_ms_2.cut!\n",
      "[2019-08-22 17:58:44]: Converting the MountainSort output following filename to Tint: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T3_filt.mda\n",
      "[2019-08-22 17:58:44]: Reading the spike data from the following file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T3_firings.mda\n",
      "[2019-08-22 17:58:44]: Reading the spike data from the following file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T3_firings.mda\n",
      "[2019-08-22 17:58:48]: Creating the following tetrode file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_ms.3!\n",
      "[2019-08-22 17:58:48]: Creating the following cut file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_ms_3.cut!\n",
      "[2019-08-22 17:58:48]: Converting the MountainSort output following filename to Tint: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T4_filt.mda\n",
      "[2019-08-22 17:58:48]: Reading the spike data from the following file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T4_firings.mda\n",
      "[2019-08-22 17:58:48]: Reading the spike data from the following file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_T4_firings.mda\n",
      "[2019-08-22 17:58:52]: Creating the following tetrode file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_ms.4!\n",
      "[2019-08-22 17:58:52]: Creating the following cut file: C:\\Users\\geba\\Desktop\\5MinRecording\\20171020-RAW-5MIN_ms_4.cut!\n",
      "[2019-08-22 17:58:52]: Creating the following EEG file: .eeg!\n",
      "[2019-08-22 17:58:55]: Creating the following EEG file: .eeg2!\n",
      "[2019-08-22 17:58:58]: Creating the following EEG file: .eeg3!\n",
      "[2019-08-22 17:59:02]: Creating the following EEG file: .eeg4!\n",
      "[2019-08-22 17:59:05]: Finished converting the following session: 20171020-RAW-5MIN!\n",
      "[2019-08-22 17:59:05]: Deleting unnecessary intermediate files from MountainSort.\n",
      "-------------------\n",
      "Finished Analysis\n"
     ]
    }
   ],
   "source": [
    "for i, current_basename in enumerate(basenames):\n",
    "    print('Analyzing set_file %d/%d: ' % (i+1, len(basenames)))\n",
    "    \n",
    "    if whiten != 'true' and automate_threshold:\n",
    "        # then you decided you want to automatically get the threshold from the .set file\n",
    "        set_filename = '%s.set' % os.path.join(directory, current_basename)\n",
    "        detect_threshold = int(get_setfile_parameter('threshold', set_filename))\n",
    "    \n",
    "    print('Using the following detect_threshold: %.2f' % (float(detect_threshold)))\n",
    "        \n",
    "    convert_bin_mountainsort(directory, current_basename, whiten=whiten, \n",
    "                             detect_interval=detect_interval,\n",
    "                             detect_sign=detect_sign, \n",
    "                             detect_threshold=detect_threshold, \n",
    "                             freq_min=freq_min,\n",
    "                             freq_max=freq_max, mask_threshold=mask_threshold, \n",
    "                             masked_chunk_size=masked_chunk_size,\n",
    "                             mask_num_write_chunks=mask_num_write_chunks, \n",
    "                             clip_size=clip_size, \n",
    "                             mask=mask,\n",
    "                             num_features=num_features,\n",
    "                             max_num_clips_for_pca=max_num_clips_for_pca,\n",
    "                             pre_spike=pre_spike, post_spike=post_spike,\n",
    "                             notch_filter=notch_filter, self=self)\n",
    "    \n",
    "    print('-------------------')\n",
    "    \n",
    "print('Finished Analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
